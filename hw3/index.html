<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
    <style>
        body {
          background-color: white;
          padding: 100px;
          width: 1000px;
          margin: auto;
          text-align: left;
          font-weight: 300;
          font-family: 'Open Sans', sans-serif;
          color: #121212;
        }
        h1, h2, h3, h4 {
          font-family: 'Source Sans Pro', sans-serif;
        }
        kbd {
          color: #121212;
        }
        code {
          background-color: #f5f5f5;
          padding: 2px 4px;
          border-radius: 4px;
          color: #c7254e;
          font-family: 'Courier New', Courier, monospace;
        }
        pre {
          background-color: #f5f5f5;
          padding: 15px;
          border-radius: 4px;
          overflow-x: auto;
        }
        .tensor-code {
            font-size: 14px; 
        }
        div.padded {
          padding-top: 30px;
        }
        .align-center {
            text-align: center;
        }
        .image-row {
            display: flex;
            justify-content: center;
            gap: 20px;
        }
        .image-container {
            text-align: center;
        }
        img {
            max-width: 400px;
            border: 1px solid #ddd;
            padding: 5px;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin-top: 20px;
        }
        td {
            padding: 10px;
            text-align: center;
            vertical-align: top;
        }
        figcaption {
            margin-top: 5px;
            font-size: 0.9em;
            color: #555;
        }
    </style>
    <title>CS184 Path Tracer Part 1 Write-Up</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>

<div class="container">
    <h1 align="middle">CS184/284A Spring 2025 Homework 3 Write-Up</h1>
    <div style="text-align: center;">Name: Sun Jingfeng</div>

    <br>

    Link to webpage:
    <a href="https://jingfengs.github.io/cs184-284a-sp25-hw-webpages/hw3/index.html">
        https://jingfengs.github.io/cs184-284a-sp25-hw-webpages/hw3/index.html
    </a>

    <br />

    Link to GitHub repository:
    <a href="https://github.com/JingfengS/cs184-284a-sp25-hw-webpages">
        https://github.com/JingfengS/cs184-284a-sp25-hw-webpages
    </a>
    
    <figure>
        <img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
        <figcaption>Path Tracer</figcaption>
    </figure>

    <h2>Overview</h2>
    <p>
        In this assignment, I implemented the core foundation of a physically-based renderer. This involved two major components: generating rays from a virtual camera to sample the scene, and calculating the intersections between those rays and scene primitives (triangles and spheres).
    </p> 
    <p>
        I learned how to bridge the gap between 2D image coordinates and 3D world space using a camera sensor model. Additionally, implementing the Möller-Trumbore algorithm gave me a deeper appreciation for the mathematical efficiency required in graphics, as we solve for barycentric coordinates and intersection time in a single step.
    </p>

    <h2>Part 1: Ray Generation and Scene Intersection</h2>
    
    <h3>Ray Generation Pipeline</h3>
    <p>
        The ray generation process bridges the 2D image space and the 3D world space. The goal is to take a normalized image coordinate \((x, y)\)—where \((0,0)\) is the bottom-left and \((1,1)\) is the top-right of the image—and transform it into a ray originating from the camera and shooting into the scene.
    </p>
    <p>
        My implementation in <code>Camera::generate_ray</code> follows these steps:
    </p>
    <ol>
        <li>
            <strong>Camera Space Transformation:</strong> 
            We define a virtual sensor plane at \(Z = -1\) in camera space. The size of this sensor is determined by the horizontal (\(hFov\)) and vertical (\(vFov\)) fields of view. I calculated the sensor dimensions using the tangent of half the FOV angles.
        </li>
        <li>
            <strong>Coordinate Mapping:</strong> 
            Since the input coordinates \((x, y)\) are normalized to \([0, 1]\), I mapped them to the sensor's coordinate system. 
            Initially, I encountered an issue where the image appeared upside down due to coordinate conventions. I fixed this by mapping the Y-coordinate such that \(0\) maps to the bottom of the sensor (negative) and \(1\) maps to the top (positive):
            <pre><code>// Transform normalized coordinates to sensor space
double sensor_x = (2 * x - 1) * tan(radians(hFov) / 2);
double sensor_y = (2 * y - 1) * tan(radians(vFov) / 2);</code></pre>
            This ensures the center of the image \((0.5, 0.5)\) aligns with the camera's optical axis \((0, 0, -1)\).
        </li>
        <li>
            <strong>World Space Transformation:</strong> 
            The ray's direction vector in camera space is \((sensor\_x, sensor\_y, -1)\). I then multiplied this vector by the camera-to-world rotation matrix (<code>c2w</code>) to orient the ray correctly in the world.
        </li>
        <li>
            <strong>Ray Creation:</strong> 
            Finally, the ray is created with its origin at the camera's position (<code>pos</code>) and the calculated normalized direction. I also initialized the ray's <code>min_t</code> and <code>max_t</code> using the near (<code>nClip</code>) and far (<code>fClip</code>) clipping planes.
        </li>
    </ol>
    <p>
        To perform supersampling (antialiasing), the <code>raytrace_pixel</code> function calls <code>generate_ray</code> multiple times per pixel. It uses a <code>gridSampler</code> to generate random offsets \((\Delta x, \Delta y)\) within the pixel area, averaging the radiance results to produce a smoother image.
    </p>

    <h3>Primitive Intersection</h3>
    <p>
        <strong>Triangle Intersection:</strong>
        For ray-triangle intersection, I implemented the <strong>Möller-Trumbore algorithm</strong>. This is a fast, efficient method that avoids computing the plane equation of the triangle explicitly. Instead, it solves for the barycentric coordinates \((1-b_1-b_2, b_1, b_2)\) and the ray parameter \(t\) simultaneously using Cramer's rule.
    </p>
    <p>
        An intersection is valid only if:
        <ul>
            <li>The time \(t\) is within the valid range \([min\_t, max\_t]\).</li>
            <li>The barycentric coordinates are valid: \(b_1 \ge 0\), \(b_2 \ge 0\), and \((b_1 + b_2) \le 1\). This ensures the point lies inside the triangle.</li>
        </ul>
    </p>

    <p>
        <strong>Sphere Intersection:</strong>
        For spheres, I used the analytic geometric approach. I substituted the ray equation \(P(t) = O + tD\) into the sphere equation \((P - C)^2 - R^2 = 0\), resulting in a quadratic equation \(At^2 + Bt + C = 0\). I solved for \(t\) using the quadratic formula. If the discriminant is non-negative, the ray intersects the sphere, and I selected the closest valid \(t\) within the clipping planes.
    </p>

    <h3>Results: Normal Shading</h3>
    <p>
        Below are images of several simple <code>.dae</code> files rendered with normal shading to verify the implementation.
    </p>

    <div style="display: flex; flex-direction: column; align-items: center;">
        <table style="width: 100%; text-align: center; border-collapse: collapse;">
          <tr>
            <td style="text-align: center;">
              <img src="images/CBempty.png" width="400px"/>
              <figcaption>CBempty.dae (Box walls)</figcaption>
            </td>
            <td style="text-align: center;">
              <img src="images/CBspheres.png" width="400px"/>
              <figcaption>CBspheres.dae (Spheres)</figcaption>
            </td>
          </tr>
          <tr>
            <td style="text-align: center;">
              <img src="images/cow.png" width="400px"/>
              <figcaption>cow.dae (Triangle Mesh)</figcaption>
            </td>
            <td style="text-align: center;">
                <img src="images/CBempty.png" width="400px" style="opacity: 0.5;"/>
                <figcaption>(Placeholder for 4th image)</figcaption>
            </td>
          </tr>
        </table>
    </div>
    
    <h2>Part 2: Bounding Volume Hierarchy</h2>
    <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit...</p>

    <h2>Part 3: Direct Illumination</h2>
    <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit...</p>

    <h2>Part 4: Global Illumination</h2>
    <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit...</p>

    <h2>Part 5: Adaptive Sampling</h2>
    <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit...</p>

    <h2>(Optional) Part 6: Extra Credit Opportunities</h2>
    <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit...</p>

</div>
</body>
</html>